<!doctype html>
<html>

<head>
  <title>Project Title</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/base/jquery-ui.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/widgets.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/widgets.js"></script>
  <script src="js/custom.js"></script>
  <style>
    .menu-widget {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text add-top-margin">
              I have extensive project experience in lots of machine learning driven applications, if you have any query or request upon the follwoing projects, feel
              free to contact me.

            </p>
          </div>
        </div>
        <!-------------------------------------------------------------------------------------------->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Project 1 Machine learning enabled high throughput automated experimentation design</h2>
            <hr>
            <p class="text add-top-margin">
              In materials science, the discovery of recipes that yield nanomaterials with defined optical properties is costly and time-consuming.
              In this study, we present a two-step framework for a machine learning-driven high-throughput microfluidic platform to rapidly produce silver nanoparticles with the desired absorbance spectrum.
              Combining a Gaussian process-based Bayesian optimization (BO) with a deep neural network (DNN), the algorithmic framework is able to converge towards the target spectrum after sampling 120 conditions.
              Once the dataset is large enough to train the DNN with sufficient accuracy in the region of the target spectrum, the DNN is used to predict the colour palette accessible with the reaction synthesis.
              While remaining interpretable by humans, the proposed framework efficiently optimizes the nanomaterial synthesis and can extract fundamental knowledge of the relationship between chemical composition and optical properties,
              such as the role of each reactant on the shape and amplitude of the absorbance spectrum.
            </p>

          </div>
       
          
            <div class="flex-item flex-column">
              <h2 class="add-top-margin">Project 2 Graph Convolutional neural network for representation of crystals</h2>
              <hr>
              <p class="text add-top-margin">
                The first and critical step of graph convolutionla neural netork is to use the data structure of graph to encode 
                the chemical molecules. Based on that, a filter with weight is applied on the graph of molecules. Each node and edge representing
                atoms and bonds are updated by aggregating the information from the neighbors. The updated data is fed into the fully connected layer,
                which is connected to the output layer with corresponding predicted results.
              </p>
          </div>

          
            <div class="flex-item flex-column">
              <h2 class="add-top-margin">Project 3 Interpretable/explainable machine learning: partial dependence plot</h2>
              <hr>
              <p class="text add-top-margin">
                The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features 
                have on the predicted outcome of a machine learning model. A partial dependence plot can show 
                whether the relationship between the target and a feature is linear, monotonic or more complex.
                The partial dependence plot is a global method: The method considers all instances and gives a 
                statement about the global relationship of a feature with the predicted outcome.
                
                In this project, we implement the calculation of partial dependence for categorical features.
                For categorical features, the partial dependence is very easy to calculate. For each of the 
                categories, we get a PDP estimate by forcing all data instances to have the same category.
                Details of the implementation will be shown subsequently.
              </p>
            </div>

          
            <div class="flex-item flex-column">
              <h2 class="add-top-margin">Project 4 Credit risk analysis</h2>
              <hr>
              <p class="text add-top-margin">
                The objective of this project is to build a model which can predict if a customer's credit account is risky or not
                based on customer's demographic information (age, gender etc.) and transation history with the bank.
                The working precess includes: (1) data cleaning (fill in missing values, handle outlier), (2) Exploratory data analysis (Pearson correlation),
                (3) Feature engineering (use PCA to extract features), (4) Models training (logistic regression, random forest,
                adaboost, gradient boosting), (5) Model selection, (6) Save models/results.
              </p>
            </div>
    
          
            <div class="flex-item flex-column">
              <h2 class="add-top-margin">Project 5 Faster training of bidirectional attention based language model </h2>
              <hr>
              <p class="text add-top-margin">
                In this project, we try to propose a novel bidirectional language model named window masking model. 
                The proposed model is trained with a new learning objective named next token prediction based on 
                the token preceding it. This method uses the text preceding the target word as input text to 
                predict the target word, namely, the concatenation of embedding from attention layer where target word
                is masked and embedding from previous residual input will be used to predict the target word. 
                To learn the proposed objective, we devise a window masking operation and an next prediction 
                mechanism inside the model based on the Transformer encoder. These components enable the proposed 
                model to compute contextualized language representations at once while maintaining the advantages 
                of the deep bidirectional architecture of language model.
              </p>



            </div>             
          </div>
        <!-------------------------------------------------------------------------------------------->
      </div>

    </div>
  </div>
</body>

</html>